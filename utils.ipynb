{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, cv2, shutil, random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_4(img):\n",
    "    fil = np.array([\n",
    "        [0, -1, 0],\n",
    "        [-1, 5, -1],\n",
    "        [0, -1, 0],\n",
    "    ])\n",
    "    img = cv2.filter2D(img,-1,fil)\n",
    "    img[img>1]=1\n",
    "    img[img<0]=0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_scale(image, center=None): #1\n",
    "    ceta = random.randint(0,90)\n",
    "    # 缩放比例scale由角度ceta决定，注意要化为弧度制\n",
    "    if ceta >= 0:\n",
    "        scale = random.randint(int(10*np.sin(ceta/180*pi)+10*np.cos(ceta/180*pi)),20)/10\n",
    "    else:\n",
    "        scale = random.randint(int(-10*np.sin(ceta/180*pi)+10*np.cos(ceta/180*pi)),20)/10\n",
    "    (h, w) = image.shape[:2] #2\n",
    "    if center is None: #3\n",
    "        center = (w // 2, h // 2) #4\n",
    "    M = cv2.getRotationMatrix2D(center, ceta, scale) #5\n",
    "    rotated = cv2.warpAffine(image, M, (w, h)) #6\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(x_paths, cateList):\n",
    "    xList=[]\n",
    "    yList=[]\n",
    "    for x_path in x_paths:\n",
    "        img = Image.open(x_path)\n",
    "        img_arr = np.array(img)/255\n",
    "        img_arr = cv2.resize(img_arr, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "#         img_arr = laplace_4(img_arr)\n",
    "#         img_arr = rotate_and_scale(img_arr)\n",
    "        xList.append(img_arr)\n",
    "        cate = x_path.split(\"\\\\\")[-2]\n",
    "        label = cateList.index(cate)\n",
    "        yList.append(label)\n",
    "    return np.float32(np.array(xList)),np.array(yList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_here(list1,list2):\n",
    "    if len(list1)==len(list2):\n",
    "        for i in list1:\n",
    "            if i in list2:\n",
    "                continue;\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(inpath, cates, batch_size, reshuffle_each_iteration=False):\n",
    "    # read and sort train data from dir\n",
    "    cateList = os.listdir(inpath)\n",
    "    if (1-is_here(cates,cateList)):\n",
    "        raise Exception(\"Invalid cates! The input categories are [\",\",\".join(str(x) for x in cates),\n",
    "                        \"], while the categories found in the folder are [\"\",\".join(str(x) for x in cateList),\"]\")\n",
    "    else:\n",
    "        catePath = [os.path.join(inpath,c) for c in cateList]\n",
    "        x_List = []\n",
    "        for c in catePath:\n",
    "            imgList = os.listdir(c)\n",
    "            x_List += [os.path.join(c,i) for i in imgList]\n",
    "        i = 0\n",
    "        while True:\n",
    "            if reshuffle_each_iteration:\n",
    "                if i == 0:\n",
    "                    paths = x_List\n",
    "                    random.shuffle(paths)\n",
    "                    x_List = paths       \n",
    "            x, y = load_imgs(x_List[i*batch_size:(i+1)*batch_size], cateList = cates)\n",
    "            y = tf.one_hot(y, len(cates))\n",
    "            yield x,y\n",
    "            i = (i+1) % (len(x_List) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_true, y_pred):\n",
    "    return tf.reduce_sum(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "def Cross_Entropy(y_true, y_pred):\n",
    "    return -tf.reduce_sum(y_true*tf.math.log(y_pred+1e-10))\n",
    "\n",
    "def CC_Pen(y_true, y_pred):\n",
    "    cc = tf.keras.losses.categorical_crossentropy(y_true,y_pred)\n",
    "    fibr = tf.constant([0.,0.,1.])\n",
    "    p = cc*tf.reduce_mean(tf.abs(y_pred-fibr))\n",
    "    loss = cc + p\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(data_path='./Images', train_path='./Train', test_path='./Test', test_ratio=0.3):\n",
    "    if bool(1-os.path.exists(train_path)): # train path是否存在\n",
    "        os.mkdir(train_path)\n",
    "    if bool(1-os.path.exists(test_path)): # test path是否存在\n",
    "        os.mkdir(test_path)\n",
    "    cates = os.listdir(data_path)\n",
    "    for c in cates:\n",
    "        cate_path = os.path.join(data_path,c)\n",
    "        imgs = os.listdir(cate_path)\n",
    "        random.shuffle(imgs)\n",
    "        num = len(imgs) # 类别c的总数\n",
    "        test_num = int(num*test_ratio)\n",
    "        train_num = num - test_num\n",
    "        print(\"Total number of {} = {}, number for training = {}, number for testing = {}.\".format(c,num,train_num,test_num))\n",
    "        # train path / test path 子目录是否存在\n",
    "        if bool(1-os.path.exists(os.path.join(train_path,c))):\n",
    "            print(\"create {} in {}\".format(c,train_path))\n",
    "            os.mkdir(os.path.join(train_path,c))\n",
    "        if bool(1-os.path.exists(os.path.join(test_path,c))):\n",
    "            print(\"create {} in {}\".format(c,test_path))\n",
    "            os.mkdir(os.path.join(test_path,c))\n",
    "        # 复制测试数据\n",
    "        for i in range(test_num):\n",
    "            shutil.copy(os.path.join(cate_path,imgs[i]), os.path.join(test_path,c))\n",
    "        # 复制训练数据\n",
    "        for i in range(train_num):\n",
    "            shutil.copy(os.path.join(cate_path,imgs[test_num+i]), os.path.join(train_path,c))\n",
    "        print(\"Succeed to divide cate {}.\\n--------------------------------------\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(\n",
    "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
    "):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
